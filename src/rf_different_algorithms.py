import numpy as np
import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import PredefinedSplit
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score


def plot_confusion_matrix(dataset, y_true, y_pred, labels, cmap):

  cm = confusion_matrix(y_true=y_true, y_pred=y_pred, normalize='true')
  class_names = labels.keys()
  df_cm = pd.DataFrame(cm,index = class_names, columns = class_names)

  plt.figure(figsize = (15,10))
  sn.heatmap(df_cm, annot=True, cmap=cmap)
  plt.title('Confusion Matrix {} Set'.format(dataset))
  plt.xlabel('Predicted')
  plt.ylabel('True')
  plt.show()


# Press the green button in the gutter to run the script.
if __name__ == '__main__':

    # importing the data
    train_data_b10 = pd.read_csv("datasets/processed/ASVspoof-LA/df_asv_train_alg_b10.csv")
    dev_data_b10 = pd.read_csv("datasets/processed/ASVspoof-LA/df_asv_dev_alg_b10.csv")
    eval_data_b10 = pd.read_csv("datasets/processed/ASVspoof-LA/df_asv_eval_alg_b10.csv")

    train_data_b20 = pd.read_csv("datasets/processed/ASVspoof-LA/df_asv_train_alg_b20.csv")
    dev_data_b20 = pd.read_csv("datasets/processed/ASVspoof-LA/df_asv_dev_alg_b20.csv")
    eval_data_b20 = pd.read_csv("datasets/processed/ASVspoof-LA/df_asv_eval_alg_b20.csv")

    # train only on audio generated by algorith 'alg'
    alg = 'A01'
    train_nat_b10 = train_data_b10.loc[train_data_b10['System ID'] == '-']
    train_alg_b10 = train_data_b10.loc[train_data_b10['System ID'] == alg]
    train_alg_b10 = train_alg_b10[0: 2580] # select a number of generated audio equal to the number of natural audio

    train_nat_b20 = train_data_b20.loc[train_data_b20['System ID'] == '-']
    train_alg_b20 = train_data_b20.loc[train_data_b20['System ID'] == alg]
    train_alg_b20 = train_alg_b20[0: 2580]

    train_data_b10 =  pd.concat([train_nat_b10, train_alg_b10], axis=0) # create the new training dataset
    train_data_b20 = pd.concat([train_nat_b20, train_alg_b20], axis=0)

    # remove nan values for test_data_b20
    list = (eval_data_b20[eval_data_b20.isna().any(axis=1)]['name'])
    eval_data_b20 = eval_data_b20[eval_data_b20.name.isin(list) == False]
    eval_data_b10 = eval_data_b10[eval_data_b10.name.isin(list) == False]

    # extract labels
    train_data_b10 = train_data_b10.sort_values(by=['name'], ascending=True)
    train_data_b20 = train_data_b20.sort_values(by=['name'], ascending=True)
    y_train_base10 = train_data_b10['label'].to_numpy()
    y_train_base20 = train_data_b20['label'].to_numpy()
    # print(y_train_base10 == y_train_base20) #check if the order is the same
    y_train = y_train_base10

    dev_data_b10 = dev_data_b10.sort_values(by=['name'], ascending=True)
    dev_data_b20 = dev_data_b20.sort_values(by=['name'], ascending=True)
    y_dev_base10 = dev_data_b10['label'].to_numpy()
    y_dev_base20 = dev_data_b20['label'].to_numpy()
    # print(y_dev_base10 == y_dev_base20) #check if the order is the same
    y_dev = y_dev_base10
    alg_dev_base10 = dev_data_b10['System ID'].to_numpy() # extract System ID
    alg_dev = alg_dev_base10

    eval_data_b10 = eval_data_b10.sort_values(by=['name'], ascending=True)
    eval_data_b20 = eval_data_b20.sort_values(by=['name'], ascending=True)
    y_eval_base10 = eval_data_b10['label'].to_numpy()
    y_eval_base20 = eval_data_b20['label'].to_numpy()
    # print(y_eval_base10 == y_eval_base20) #check if the order is the same
    y_eval = y_eval_base10
    alg_eval_base10 = eval_data_b10['System ID'].to_numpy()
    alg_eval = alg_eval_base10

    # remove names, System ID and labels columns
    X_train_b10 = train_data_b10.iloc[:, :-2]
    X_train_b10 = X_train_b10.iloc[:, 1:]
    X_train_b20 = train_data_b20.iloc[:, :-2]
    X_train_b20 = X_train_b20.iloc[:, 1:]

    X_dev_b10 = dev_data_b10.iloc[:, :-2]
    X_dev_b10 = X_dev_b10.iloc[:, 1:]
    X_dev_b20 = dev_data_b20.iloc[:, :-2]
    X_dev_b20 = X_dev_b20.iloc[:, 1:]

    X_eval_b10 = eval_data_b10.iloc[:, :-2]
    X_eval_b10 = X_eval_b10.iloc[:, 1:]
    X_eval_b20 = eval_data_b20.iloc[:, :-2]
    X_eval_b20 = X_eval_b20.iloc[:, 1:]

    X_train = np.column_stack((X_train_b10, X_train_b20))
    X_dev = np.column_stack((X_dev_b10, X_dev_b20))
    X_eval = np.column_stack((X_eval_b10, X_eval_b20))

    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, shuffle=True, train_size=0.8)

    # for random search, concatenate training and validation set
    X = np.concatenate((X_train, X_valid), axis=0)
    y = np.concatenate((y_train, y_valid), axis=0)

    # to avoid k-fold cross validation in GridSearchCV and use instead the training-validation split defined before
    # Create a list where train data indices are -1 and validation data indices are 0
    split_index = [-1] * len(X_train) + [0] * len(X_valid)

    # Use the list to create PredefinedSplit
    pds = PredefinedSplit(test_fold=split_index)

    n_estimators = [100]  # number of trees in the forest of the model (default value is 100)
    max_depth = [15, 25, 30]  # maximum depth of each tree(default value is None, which means that each tree will expand until every leaf is pure)
    min_samples_split = [2]  # minimum number of samples required to split an internal leaf node. (default value is 2, which means that an internal node must have at least two samples before it can be split to have a more specific classification)
    min_samples_leaf = [1]  # minimum number of samples required to be at a leaf node (default is 1, which means that every leaf must have at least 1 sample that it classifies)

    params = dict(n_estimators=n_estimators, max_depth=max_depth,
                  min_samples_split=min_samples_split,
                  min_samples_leaf=min_samples_leaf)

    clf = RandomForestClassifier()

    gs = GridSearchCV(clf, params, cv=pds, scoring='accuracy', verbose=10)

    # fitting the model (on X and y)
    gs.fit(X, y)

    # print best parameter after tuning
    print("Best parameters:", gs.best_params_)
    print("Best validation accuracy:", gs.best_score_)

    # best configurations
    best_clf = gs.best_estimator_
    best_clf.fit(X_train, y_train)

    y_dev_pred = best_clf.predict(X_dev)
    y_dev_pred = np.array(y_dev_pred)  # predicted labels

    print("Development accuracy:", accuracy_score(y_dev, y_dev_pred))
    print("Development F1 score:", f1_score(y_dev, y_dev_pred, average='macro'))

    y_eval_pred = best_clf.predict(X_eval)
    y_eval_pred = np.array(y_eval_pred)  # predicted labels

    print("Evaluation accuracy:", accuracy_score(y_eval, y_eval_pred))
    print("Evaluation F1 score:", f1_score(y_eval, y_eval_pred, average='macro'))

    labels = {'Natural': 0, 'A01': 1, 'A02': 2, 'A03': 3, 'A04': 4, 'A05': 5, 'A06': 6}

    A01 = [1 if x == 'A01' else x for x in alg_dev]
    A02 = [2 if x == 'A02' else x for x in A01]
    A03 = [3 if x == 'A03' else x for x in A02]
    A04 = [4 if x == 'A04' else x for x in A03]
    A05 = [5 if x == 'A05' else x for x in A04]
    A06 = [6 if x == 'A06' else x for x in A05]
    A = [0 if x == '-' else x for x in A06]

    plot_confusion_matrix('Development',y_dev*A, y_dev_pred*A, labels, 'Reds')

    # labels = {'Natural': 0, 'Fake': 1}
    labels = {'Natural': 0, 'A07': 7, 'A08': 8, 'A09': 9, 'A10': 10, 'A11': 11, 'A12': 12, 'A13': 13, 'A14': 14,
              'A15': 15, 'A16': 16, 'A17': 17, 'A18': 18, 'A19': 19}

    # convert 'A01' in 1, 'A02' in 2 and so on ..
    A07 = [7 if x == 'A07' else x for x in alg_eval]
    A08 = [8 if x == 'A08' else x for x in A07]
    A09 = [9 if x == 'A09' else x for x in A08]
    A10 = [10 if x == 'A10' else x for x in A09]
    A11 = [11 if x == 'A11' else x for x in A10]
    A12 = [12 if x == 'A12' else x for x in A11]
    A13 = [13 if x == 'A13' else x for x in A12]
    A14 = [14 if x == 'A14' else x for x in A13]
    A15 = [15 if x == 'A15' else x for x in A14]
    A16 = [16 if x == 'A16' else x for x in A15]
    A17 = [17 if x == 'A17' else x for x in A16]
    A18 = [18 if x == 'A18' else x for x in A17]
    A19 = [19 if x == 'A19' else x for x in A18]
    A = [0 if x == '-' else x for x in A19]

    plot_confusion_matrix('Evaluation', y_eval * A, y_eval_pred * A, labels, 'Reds')





